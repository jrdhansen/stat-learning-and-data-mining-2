together <- rbind(tableDWE, tableDWN, tableTOSS, tableRWN, tableRWE)
# This function removes the "%" sign and changes values to numeric for
# calculation of the "Diff" column
removePct_toNum <- function(cellVal) {
cellVal <- as.character(cellVal) %>%
gsub("%", "", .) %>%
as.numeric()
return(cellVal)
}
# Determine value of column: will either be a "—" or a number value
# If it's "—" then replace it with a 0, else turn it into the numeric value
# using the removePct_toNum function
dash_or_val <- function(cellVal) {
if(cellVal == "—") {
cellVal <- 0
} else {
cellVal <- removePct_toNum(cellVal)
}
return(cellVal)
}
calcDiff <- function(stateRow) {
# Convert values for these three columns to numeric using dash_or_val function
demct <- dash_or_val(stateRow$Dem.)
repub <- dash_or_val(stateRow$Rep.)
other <- dash_or_val(stateRow$Oth.)
# Determine which is a larger value: "Dem." or "Oth.", will be assigned to the
# dem_or_oth for calculating the Diff column
if(demct > other) {
dem_or_oth <- demct
} else {
dem_or_oth <- other
}
# Calculate the value of the Diff column:
if((repub == 0) && (other == 0)) {
stateRow$Diff <- 100
} else if((demct == 0) && (other == 0)) {
stateRow$Diff <- -100
} else {
stateRow$Diff <- (dem_or_oth - repub)
}
return(stateRow)
}
# Add a new blank column to be populated
together$Diff <- NA
# Go through each row and populate the new Diff column
for (i in 1:nrow(together)) {
together[i, ] <- calcDiff(together[i, ])
}
View(together)
nrow(together)
source('C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/Juergen__DataTech/hw2/scratch,dev_script.R', echo=TRUE)
i = 1
calcDiff(together[i, ])
"54%" == "-"
stateRow <- (together[i, ])
# Convert values for these three columns to numeric using dash_or_val function
demct <- dash_or_val(stateRow$Dem.)
repub <- dash_or_val(stateRow$Rep.)
other <- dash_or_val(stateRow$Oth.)
cellVal <- stateRow$Dem.
if(cellVal == "—") {
cellVal <- 0
} else {
cellVal <- removePct_toNum(cellVal)
}
cellVal
library(XML)
# GET the NYT website (had to use paste0() function since the URL didn't fit on
# a single line).
# NOTEWORTHY: had to remove the "s" from "https" to get it to work.
NYT_url <- paste0("http://www.nytimes.com/interactive/2018/11/06/us/",
"elections/results-senate-elections.html")
doc <- GET(NYT_url)
# Store the document in the docxml object using htmlParse function. I tried
# using xmlParse, but it didn't play nicely with this web address.
docNYT <- htmlParse(doc)
# This stores the data on the website that's already in table format into tables
# in R. There are 5 of these such tables. We have to put them together and
# create an additional column.
NYT_tables <- readHTMLTable(docNYT, header = TRUE)
tableDWE <- as.data.frame(NYT_tables[8])
tableDWN <- as.data.frame(NYT_tables[9])
tableTOSS <- as.data.frame(NYT_tables[10])
tableRWN <- as.data.frame(NYT_tables[11])
tableRWE <- as.data.frame(NYT_tables[12])
# Give all the tables the same column names so they can be bound into one table.
names(tableDWN) <- names(tableDWE)
names(tableTOSS) <- names(tableDWE)
names(tableRWN) <- names(tableDWE)
names(tableRWE) <- names(tableDWE)
# Put all of the tables together into one.
together <- rbind(tableDWE, tableDWN, tableTOSS, tableRWN, tableRWE)
# Change the column names to look like what the prompt wants
names(together) <- gsub("NULL\\.", "", names(together)) %>%
gsub("\\.\\.", "% ", .)
# This function removes the "%" sign and changes values to numeric for
# calculation of the "Diff" column
removePct_toNum <- function(cellVal) {
cellVal <- as.character(cellVal) %>%
gsub("%", "", .) %>%
as.numeric()
return(cellVal)
}
# Determine value of column: will either be a "—" or a number value
# If it's "—" then replace it with a 0, else turn it into the numeric value
# using the removePct_toNum function
dash_or_val <- function(cellVal) {
if(cellVal == "—") {
cellVal <- 0
} else {
cellVal <- removePct_toNum(cellVal)
}
return(cellVal)
}
calcDiff <- function(stateRow) {
# Convert values for these three columns to numeric using dash_or_val function
demct <- dash_or_val(stateRow$Dem.)
repub <- dash_or_val(stateRow$Rep.)
other <- dash_or_val(stateRow$Oth.)
# Determine which is a larger value: "Dem." or "Oth.", will be assigned to the
# dem_or_oth for calculating the Diff column
if(demct > other) {
dem_or_oth <- demct
} else {
dem_or_oth <- other
}
# Calculate the value of the Diff column:
if((repub == 0) && (other == 0)) {
stateRow$Diff <- 100
} else if((demct == 0) && (other == 0)) {
stateRow$Diff <- -100
} else {
stateRow$Diff <- (dem_or_oth - repub)
}
return(stateRow)
}
# Add a new blank column to be populated
together$Diff <- NA
# Go through each row and populate the new Diff column
for (i in 1:nrow(together)) {
together[i, ] <- calcDiff(together[i, ])
}
library(XML)
# GET the NYT website (had to use paste0() function since the URL didn't fit on
# a single line).
# NOTEWORTHY: had to remove the "s" from "https" to get it to work.
NYT_url <- paste0("http://www.nytimes.com/interactive/2018/11/06/us/",
"elections/results-senate-elections.html")
doc <- GET(NYT_url)
# Store the document in the docxml object using htmlParse function. I tried
# using xmlParse, but it didn't play nicely with this web address.
docNYT <- htmlParse(doc)
# This stores the data on the website that's already in table format into tables
# in R. There are 5 of these such tables. We have to put them together and
# create an additional column.
NYT_tables <- readHTMLTable(docNYT, header = TRUE)
tableDWE <- as.data.frame(NYT_tables[8])
tableDWN <- as.data.frame(NYT_tables[9])
tableTOSS <- as.data.frame(NYT_tables[10])
tableRWN <- as.data.frame(NYT_tables[11])
tableRWE <- as.data.frame(NYT_tables[12])
# Give all the tables the same column names so they can be bound into one table.
names(tableDWN) <- names(tableDWE)
names(tableTOSS) <- names(tableDWE)
names(tableRWN) <- names(tableDWE)
names(tableRWE) <- names(tableDWE)
# Put all of the tables together into one.
together <- rbind(tableDWE, tableDWN, tableTOSS, tableRWN, tableRWE)
# Change the column names to look like what the prompt wants
names(together) <- gsub("NULL\\.", "", names(together)) %>%
gsub("\\.\\.", "% ", .)
# This function removes the "%" sign and changes values to numeric for
# calculation of the "Diff" column
removePct_toNum <- function(cellVal) {
cellVal <- as.character(cellVal) %>%
gsub("%", "", .) %>%
as.numeric()
return(cellVal)
}
# Determine value of column: will either be a "—" or a number value
# If it's "—" then replace it with a 0, else turn it into the numeric value
# using the removePct_toNum function
dash_or_val <- function(cellVal) {
if(cellVal == "—") {
cellVal <- 0
} else {
cellVal <- removePct_toNum(cellVal)
}
return(cellVal)
}
calcDiff <- function(stateRow) {
# Convert values for these three columns to numeric using dash_or_val function
demct <- dash_or_val(stateRow$Dem.)
repub <- dash_or_val(stateRow$Rep.)
other <- dash_or_val(stateRow$Oth.)
# Determine which is a larger value: "Dem." or "Oth.", will be assigned to the
# dem_or_oth for calculating the Diff column
if(demct > other) {
dem_or_oth <- demct
} else {
dem_or_oth <- other
}
# Calculate the value of the Diff column:
if((repub == 0) && (other == 0)) {
stateRow$Diff <- 100
} else if((demct == 0) && (other == 0)) {
stateRow$Diff <- -100
} else {
stateRow$Diff <- (dem_or_oth - repub)
}
return(stateRow)
}
# Add a new blank column to be populated
together$Diff <- NA
# Go through each row and populate the new Diff column
for (i in 1:nrow(together)) {
together[i, ] <- calcDiff(together[i, ])
}
# Arrange it like the problem says to do
together[order(together$Diff, decreasing = TRUE) , ]
View(together)
# Arrange it like the problem says to do
together[order(together$Diff, decreasing = TRUE) , ]
# Arrange it like the problem says to do
together <- together[order(together$Diff, decreasing = TRUE) , ]
View(together)
# Change the name of the Diff column to be "Diff [Dem. (or Oth.) - Rep.]"
colnames(together)[which(names(together) == "Diff")] <-
"Diff [Dem. (or Oth.) - Rep.]"
together
# Define directory, set working directory.
directory <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML")
# setwd(directory)
# First, obtain the file names for all XML files via the
# list.files() function.
xml_files <- list.files(path = directory)
# Initialize a blank vector (to start the dataframe. Seems a bit clumsy,
# but it worked, so I left it. Didn't want to mess things up.)
finalData <- vector()
# Loop through all files, extracting the start and end times,
# calculating the difference. Create a new row of these 3 values,
# append it to the data frame.
for (i in 1:length(xml_files)) {
# Store the document in the docxml object using xmlTreeParse function
file_name <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML/",
xml_files[i])
doc <- xmlTreeParse(file_name, useInternalNodes = TRUE)
info <- xmlRoot(doc)
# Then extract the RecordingStartTime and RecordingEndTime
# from each XML file. Calculate the time difference (TimeDiff) as
# (RecordingEndTime - RecordingStartTime) in minutes.
startOrig <- xmlValue(info[["RecordingStartTime"]])
endOrig <- xmlValue(info[["RecordingEndTime"]])
diff <- (parse_date(endOrig) - parse_date(startOrig)) %>%
gsub("[^[[:digit:]]]", "", .) %>%
as.numeric() %>%
round(., digits = 5)
# diff is originally in terms of hours, so convert to minutes
diff <- (diff * 60)
# Final dataframe row
final_row <- c(startOrig, endOrig, diff)
# Add the new row to the bottom of the dataframe
finalData <- rbind(finalData, final_row)
}
# Get rid of weird row names, and add the desired column names.
rownames(finalData) <- c()
colnames(finalData) <- c("RecordingStartTime",
"RecordingEndTime",
"TimeDiff")
# This is a matrix, and the problem wants a dataframe, so convert to a df.
finalData <- as.data.frame(finalData)
# Show the first 6 lines. No need to sort the dataframe.
head(finalData)
# Plot a basic histogram of the time differences
finalData$TimeDiff <- as.character(finalData$TimeDiff) %>%
as.numeric()
hist(finalData$TimeDiff,
main = "Histogram of Time Differences\n(End - Beg)",
xlab = "Difference (minutes)",
ylab = "Number of Occurences",
ylim = c(0, 40),
xlim = c(0, 4000),
breaks = 20)
# Store the outliers (we'll say this is anything over 90 minutes,
# as the class will typically have gone no more than 5 minutes over,
# which would be 80 minutes long.)
outliers <- finalData[which(finalData$TimeDiff > 90), ]
# We can see that the only outlier occurred on October 9th
# (We know ISO 8601 date format is "YYYY-MM-DD".)
for (i in 1:nrow(outliers)) {
print((outliers$RecordingStartTime))
}
library(XML)
library(magrittr)
library(parsedate)
# Define directory, set working directory.
directory <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML")
# setwd(directory)
# First, obtain the file names for all XML files via the
# list.files() function.
xml_files <- list.files(path = directory)
# Initialize a blank vector (to start the dataframe. Seems a bit clumsy,
# but it worked, so I left it. Didn't want to mess things up.)
finalData <- vector()
# Loop through all files, extracting the start and end times,
# calculating the difference. Create a new row of these 3 values,
# append it to the data frame.
for (i in 1:length(xml_files)) {
# Store the document in the docxml object using xmlTreeParse function
file_name <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML/",
xml_files[i])
doc <- xmlTreeParse(file_name, useInternalNodes = TRUE)
info <- xmlRoot(doc)
# Then extract the RecordingStartTime and RecordingEndTime
# from each XML file. Calculate the time difference (TimeDiff) as
# (RecordingEndTime - RecordingStartTime) in minutes.
startOrig <- xmlValue(info[["RecordingStartTime"]])
endOrig <- xmlValue(info[["RecordingEndTime"]])
diff <- (parse_date(endOrig) - parse_date(startOrig)) %>%
gsub("[^[[:digit:]]]", "", .) %>%
as.numeric() %>%
round(., digits = 5)
# diff is originally in terms of hours, so convert to minutes
diff <- (diff * 60)
# Final dataframe row
final_row <- c(startOrig, endOrig, diff)
# Add the new row to the bottom of the dataframe
finalData <- rbind(finalData, final_row)
}
# Get rid of weird row names, and add the desired column names.
rownames(finalData) <- c()
colnames(finalData) <- c("RecordingStartTime",
"RecordingEndTime",
"TimeDiff")
# This is a matrix, and the problem wants a dataframe, so convert to a df.
finalData <- as.data.frame(finalData)
# Show the first 6 lines. No need to sort the dataframe.
head(finalData)
# Plot a basic histogram of the time differences
finalData$TimeDiff <- as.character(finalData$TimeDiff) %>%
as.numeric()
hist(finalData$TimeDiff,
main = "Histogram of Time Differences\n(End - Beg)",
xlab = "Difference (minutes)",
ylab = "Number of Occurences",
ylim = c(0, 40),
xlim = c(0, 4000),
breaks = 20)
# Store the outliers (we'll say this is anything over 90 minutes,
# as the class will typically have gone no more than 5 minutes over,
# which would be 80 minutes long.)
outliers <- finalData[which(finalData$TimeDiff > 90), ]
# We can see that the only outlier occurred on October 9th
# (We know ISO 8601 date format is "YYYY-MM-DD".)
for (i in 1:nrow(outliers)) {
print((outliers$RecordingStartTime))
}
@
# Load necessary libraries
library(XML)
library(magrittr)
library(parsedate)
# Define directory, set working directory.
directory <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML")
# setwd(directory)
# First, obtain the file names for all XML files via the
# list.files() function.
xml_files <- list.files(path = directory)
# Initialize a blank vector (to start the dataframe. Seems a bit clumsy,
# but it worked, so I left it. Didn't want to mess things up.)
finalData <- vector()
# Loop through all files, extracting the start and end times,
# calculating the difference. Create a new row of these 3 values,
# append it to the data frame.
for (i in 1:length(xml_files)) {
# Store the document in the docxml object using xmlTreeParse function
file_name <- paste0("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/",
"Juergen__DataTech/hw2/Symanzik_stuff/HW02_Data/XML/",
xml_files[i])
doc <- xmlTreeParse(file_name, useInternalNodes = TRUE)
info <- xmlRoot(doc)
# Then extract the RecordingStartTime and RecordingEndTime
# from each XML file. Calculate the time difference (TimeDiff) as
# (RecordingEndTime - RecordingStartTime) in minutes.
startOrig <- xmlValue(info[["RecordingStartTime"]])
endOrig <- xmlValue(info[["RecordingEndTime"]])
diff <- (parse_date(endOrig) - parse_date(startOrig)) %>%
gsub("[^[[:digit:]]]", "", .) %>%
as.numeric() %>%
round(., digits = 5)
# diff is originally in terms of hours, so convert to minutes
diff <- (diff * 60)
# Final dataframe row
final_row <- c(startOrig, endOrig, diff)
# Add the new row to the bottom of the dataframe
finalData <- rbind(finalData, final_row)
}
# Get rid of weird row names, and add the desired column names.
rownames(finalData) <- c()
colnames(finalData) <- c("RecordingStartTime",
"RecordingEndTime",
"TimeDiff")
# This is a matrix, and the problem wants a dataframe, so convert to a df.
finalData <- as.data.frame(finalData)
# Show the first 6 lines. No need to sort the dataframe.
head(finalData)
# Plot a basic histogram of the time differences
finalData$TimeDiff <- as.character(finalData$TimeDiff) %>%
as.numeric()
hist(finalData$TimeDiff,
main = "Histogram of Time Differences\n(End - Beg)",
xlab = "Difference (minutes)",
ylab = "Number of Occurences",
ylim = c(0, 40),
xlim = c(0, 4000),
breaks = 20)
# Store the outliers (we'll say this is anything over 90 minutes,
# as the class will typically have gone no more than 5 minutes over,
# which would be 80 minutes long.)
outliers <- finalData[which(finalData$TimeDiff > 90), ]
# We can see that the only outlier occurred on October 9th
# (We know ISO 8601 date format is "YYYY-MM-DD".)
for (i in 1:nrow(outliers)) {
print(parse_iso_8601(outliers$RecordingStartTime))
}
@
finalData
# Necessary libraries
library(kknn)
library(fcd)
library(mclust)
library(speccalt)
library(dplyr)
library(kernlab)
# Set working directory
setwd("C:/Users/jrdha/OneDrive/Desktop/USU_Fa2018/Moon__SLDM2/hw6/problem2")
#======================== READ IN, FORMAT DATA =================================
#===============================================================================
# NOTE: used the helpful code that Matt shared on Piazza to do this part.
# need R.utils package installed and files downloaded in working directory.
# gunzip the files
R.utils::gunzip("train-images-idx3-ubyte.gz")
R.utils::gunzip("train-labels-idx1-ubyte.gz")
R.utils::gunzip("t10k-images-idx3-ubyte.gz")
R.utils::gunzip("t10k-labels-idx1-ubyte.gz")
# helper function for visualization
show_digit = function(arr784, col = gray(12:1 / 12), ...) {
image(matrix(as.matrix(arr784[-785]), nrow = 28)[, 28:1], col = col, ...)
}
# load image files
load_image_file = function(filename) {
ret = list()
f = file(filename, 'rb')
readBin(f, 'integer', n = 1, size = 4, endian = 'big')
n    = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = FALSE)
close(f)
data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))
}
# load label files
load_label_file = function(filename) {
f = file(filename, 'rb')
readBin(f, 'integer', n = 1, size = 4, endian = 'big')
n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)
close(f)
y
}
# load images
train = load_image_file("train-images-idx3-ubyte")
test  = load_image_file("t10k-images-idx3-ubyte")
# load labels
train$y = as.factor(load_label_file("train-labels-idx1-ubyte"))
test$y  = as.factor(load_label_file("t10k-labels-idx1-ubyte"))
# view test image
# show_digit(train[10000, ])
#=================== SubSamp FUNCTION ==========================================
#===============================================================================
# SubSamp takes as arguments: givenData and sampSize. Generates (and returns) a
# random sub-sample of sampSize from givenData.
SubSamp <- function(givenData, sampSize){
samp <- dplyr::sample_n(tbl = givenData, size = sampSize, replace = FALSE)
return(samp)
}
#==== GENERATE SUBSAMPLES TO BE USED FOR K-MEANS AND SPECTRAL CLUSTERING =======
#===============================================================================
# Set seed for reproducibility
set.seed(2345)
# selected sigma = 5.011872e-06
sigma = 5.011872 * (10^(-6))
#=============== APPLYING SPECTRAL CLUSTERING TO TEST DATA =====================
#===============================================================================
set.seed(2345)
ARI.sc.test <- specc(as.matrix(dplyr::select(test, -y)),
centers = 10,
kernel = "rbfdot",
kpar = list("sigma" = sig))
ARI.sc.test.val <- adjustedRandIndex(ARI.sc.test@.Data, test$y)
ARI.sc.test.val
ARI.sc.test <- specc(as.matrix(dplyr::select(test, -y)),
centers = 10,
kernel = "rbfdot",
kpar = list("sigma" = sigma))
ARI.sc.test.val <- adjustedRandIndex(ARI.sc.test@.Data, test$y)
ARI.sc.test.val
